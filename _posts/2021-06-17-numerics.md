---
layout: distill
title: Finite what?
description: A non-comprehensive guide to solving numerical problems
date: 2021-06-17

authors:
  - name: Patrick Zimbrod
  - affiliations:
    name: Applied Computer Science, Augsburg
  

bibliography: 2021-06-17-numerics.bib

# Below is an example of injecting additional post-specific styles.
# If you use this post as a template, delete this _styles block.
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }

---

> TL;DR: There's no such thing as the best code / software / method to solve any given type of physical (or chemical / biological etc.) real-world phenomenon. It takes thorough care to select a method that is optimal in a mathematical sense for a given problem. However, with an understanding of the nature of the underlying equations, it is very much possible to make a well educated guess on what algorithm will perform well.

# Introduction

No matter where you're asking around within the industry nowadays, there's a good chance that the majority of people will tell you that digitalization and hence simulation is an "evergreen" trend in product development.

In a world where there's a company trying to sell you "the best simulation tool on the planet" around every other corner, you'd also be forgiven to think that some methods are just clearly better than others.

Truthfully, every tool or method or behind it has its niche where it shines. The job as a scientist / engineer is primarily to find the best tool for the job whilst keeping an open mind. Otherwise you'd soon be too narrowed down on one solution, or in the words of the famous Abraham Maslow <d-cite key="maslowPsychologyBeing2013"></d-cite>:

> "I suppose it is tempting, if the only tool you have is a hammer, to treat everything as if it were a nail."

# What can we choose from?

From this point, to simplify things, we will talk about techniques for numerical modelling of partial differential equations (PDEs) when mentioning the term simulation. This means that we're constraining ourselves to modelling processes that occur in nature and are therefore continuous. Also, the typical problem imposed is how to deal with the various derivative terms in space (and often in time as well) which can be of any order, linear or nonlinear with constant or varying coefficients.

We will just briefly explore the most prevalent methods that at the same time covers the widely available commercial codes. To give a little structure to this list, I will present them in loose historical order.

## Finite Difference Method (FDM)

This technique can be regarded as the most "primitive" alternative to solving this type of problems and dates back to its origins more than 100 years ago by Richardson <d-cite key="richardsonIXApproximateArithmetical1911"></d-cite>: The idea is as simple as charming: You look at the posed problem on a given domain only at discrete points, calculate the differentials between them and interpolate the rest. Now you'd be right to ask whether that wasn't a little simple for notoriously hard to solve problems (by hand) and you'd be absolutely right.

In fact, the error of this approximation is of linear order with the step size, which is not good when talking about accuracy <d-cite key="iserlesFirstCourseNumerical2009"></d-cite>. Also, this might lead to serious stability issues. Say, you're modelling a domain where heat transfer occurs and the solution is in some way oscillating. Then you would get vastly different results depending on your grid size. For example, if your "probing points" just so happen to coincide with two peaks of your solution, you would get a linear (or even worse, constant) slope by the FDM model - where actually the solution is harmonic. Of course, a trained user would probably chose a grid size way smaller than in this example, but this goes to show what order of accuracy can mean in a worst-case scenario.

On the other hand, the FDM gives a very universal way of tackling PDEs. You'd call it a jack of all trades, but master of none.

## Finite Volume Method (FVM)

In contrast to the FDM, we're now not considering singular points or vertices of your domain, but rather a cell where inside a portion of the overall physics happens. This way of thinking is fundamentally different and one could argue that it stems from a more "engineering" way of thinking. The motivation stems from the idea that you would split an integral solution of a problem into a specific (finite) amount of subdomains, each with their own solution. This method is especially prominent in fluid dynamics, where dealing with conservation equations is quite common.

To this day, FVM remains a popular choice for dealing with flow phenomena of many sorts. But this method also is not without its flaws. We will try to sketch the most problematic in short. For now, reimagine the idea of FVM in terms of neighboring cells. You can then convince yourself that in a 3D domain, each volume shares a common face with a neighboring cell. Unfortunately due to the way FVM is set up, the values of one cell needs to be reconstructed by the values on the faces. This leads to the problem that for one face, you have multiple values that the one on the face could assume. So how choose? This kind of discontinuity poses an important problem.

## Finite Element Method (FEM)

The Finite Element Method has a history that is somewhat hard to sketch in a historically correct manner. Initially, the way of coming up with this method was also closely linked to a given problem similar to FVM, just in this case it was solid mechanics. You would similarly divide the domain into elements and calculate individual solutions each. The original formulation of the FEM was also very specific to static problems in mechanics, where you would assemble a stiffness matrix and solve it by common linear algebra.

However, state-of-the-art FEM does not share many of its DNA with what was just presented. It is rather a more powerful approach of dealing with all kinds of phenomena. The modern interpretation of this technique is known as the Galerkin Finite Element Method. This can in turn be further divided into continuous (CG-FEM) or discontinuous (DG-FEM) methods.

The basic idea more or less goes as follows: We are not trying to obtain the accurate solution of the problem in terms of the function itself, but are rather seeking a functional approximation - much of what you would do with a Taylor series (polynomial approximation) to an arbitrary function. The output of such a simulation is therefore not the actual function itself discretized in space, but rather the coefficients of the set of functions that you're trying to approximate the solution with. As you might already have guessed, this is a much more mathematical way of thinking in contrast to the more hands-on approach how the method was originally conceived.

## Why isn't there the one thing to rule them all?

The answer to this question is at the same time remarkably simple and complicated at the same time. Wolpert and Macready have put this in a beautifully elegant way that has become famous as one formulation of a "no free lunch theorem" <d-cite key="wolpertNoFreeLunch1997"></d-cite>:

> "[...] for any algorithm, any elevated performance over one class of problems is offset by performance over another class. "

This fact about optimization algorithms (and this is what numerical PDE solvers ultimately are) gives a useful introduction and baseline to our following discussion. From this point, to simplify things, we will talk about techniques for numerical modelling of partial differential equations (PDEs) when mentioning the term simulation.

So when you're trying to solve a physical phenomenon that is modelled by a PDE, you are not to expect that the (mathematically) optimal choice of algorithm for this problem will perform equally well in another type of problem. That is, in short, the simple part of our answer.

The more specific answer lies in the nature of PDEs. When talking about equations of second order - which, surprisingly, an overwhelming fraction of real world physical phenomena is covered by - we can make a classification into three separate types: hyperbolic, parabolic and elliptic. If you're more into the mathematics behind, I suggest some sort of introductory book on analysis.

Depending on the terms occuring in the physics you're modelling, it can be advantageous to chose one method over the other.
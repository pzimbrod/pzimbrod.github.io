---
layout: distill
title: Finite Elements - The forbidden child?
description: An example of an overwhelmingly useful collaboration between Engineers and Mathematicians
date: 2021-06-16

authors:
  - name: Patrick Zimbrod
    affiliations:
      name: Applied Computer Science, Augsburg
  

bibliography: 2021-06-17-numerics.bib

# Below is an example of injecting additional post-specific styles.
# If you use this post as a template, delete this _styles block.
_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }

---

The Finite Element Method has a history that is somewhat hard to sketch in a historically correct manner. Initially, the way of coming up with this method was also closely linked to a given problem similar to FVM, just in this case it was solid mechanics. You would similarly divide the domain into elements and calculate individual solutions each. The original formulation of the FEM was also very specific to static problems in mechanics, where you would assemble a stiffness matrix and solve it by common linear algebra.

However, state-of-the-art FEM does not share much of its DNA with what was just presented. It is rather a more powerful approach of dealing with all kinds of phenomena. The modern interpretation of this technique is known as the Galerkin Finite Element Method. This can in turn be further divided into continuous (CG-FEM) or discontinuous (DG-FEM) methods.

The basic idea more or less goes as follows: We are not trying to obtain the accurate solution of the problem in terms of the function itself, but are rather seeking a functional approximation - much of what you would do with a Taylor series (polynomial approximation) to an arbitrary function. The output of such a simulation is therefore not the actual function itself discretized in space, but rather the coefficients of the set of functions that you're trying to approximate the solution with. As you might already have guessed, this is a much more mathematical way of thinking in contrast to the more hands-on approach how the method was originally conceived <d-cite key="j.n.reddyIntroductionFiniteElement2019"></d-cite>.

The mathematics behind the FEM as well routes from another discipline, namely functional analysis. We here consider a so called variational formulation of a weak form derived from the problem at hand.

$$
\int\limits_{\partial \Omega} \frac{\partial q}{\partial t} \phi_j dx + \int\limits_{\partial \Omega} \frac{\partial f(q)}{\partial x} \phi_j dx =0
$$

The weak form is obtained by integrating the PDE over the domain $\Omega$ and multiplying it with a so called set of test functions $\phi_i$. Here, the nonlinear terms that we encountered in the Finite Volume section are summarized in a differential operator $f(q)$. We then seek to approximate the exact function $q(x)$ that solves the problem by an approximate representation $\tilde{q}(x)$, comprised of certain basis functions $\Psi_i(x)$:

$$
\tilde{q}(x) = \sum\limits_{i} a_i \Psi_i(x)
$$

Often enough, these functions are polynomials of special kind that possess certain properties regarding their definition range. One popular example are Lagrange polynomials that have the fundamental property of only taking the value 1 at one and 0 at every other node that comprise the geometry of one finite element.

Finally, as we are not modelling the problem exactly, we set the right-hand side equal to a residual that must tend to zero as we approach the real solution. Here, we achieve this by systematically approaching the right basis coefficients $a_i$.

As we can see above, there is also some integration that needs to take place here. That means we encounter the same problem that we had with the Finite Volume formulation - how do we calculate these numerically?
Instead of converting these into hull integrals, we take a different approach here. We are here considering a finite set of elements that each contain a certain amount of nodes, depending on the element type. Within these elements, we use the Gauss quadrature rule to perform explicit integration. This can be formulated in a way that the integration yields even exact results for a certain choice of basis functions.
So in some way, we again may thank one of the greatest mathematicians in history for letting us perform this difficult task, yet with a completely different approach.

Now what are the pitfalls of this approach? Depending on the choice of the function basis, the element size and the type of problem, we may encounter convergence issues much similar to the other methods. In this case, as we're trying to minimize a certain residual, this value might not converge to zero, hence yielding a suboptimal approximation <d-cite key="ernTheoryPracticeFinite2013"></d-cite>.